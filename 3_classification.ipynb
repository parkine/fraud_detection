{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['pylab']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pylab\n",
    "import sklearn as sk\n",
    "%pylab inline\n",
    "\n",
    "df = pd.read_csv('card_transdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#divide the dataset into train and test data set\n",
    "\n",
    "#divide target class and the rest of features\n",
    "X = df.drop(\"fraud\", axis=1)\n",
    "y = df[\"fraud\"]\n",
    "\n",
    "#divide the dataset into train and test data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 7 columns):\n",
      "distance_from_home                1000000 non-null float64\n",
      "distance_from_last_transaction    1000000 non-null float64\n",
      "ratio_to_median_purchase_price    1000000 non-null float64\n",
      "repeat_retailer                   1000000 non-null float64\n",
      "used_chip                         1000000 non-null float64\n",
      "used_pin_number                   1000000 non-null float64\n",
      "online_order                      1000000 non-null float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 53.4 MB\n"
     ]
    }
   ],
   "source": [
    "X[:10]\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 115 ms, sys: 7.9 ms, total: 123 ms\n",
      "Wall time: 123 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train the MultinomialNB model \n",
    "nb_model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.3 s, sys: 11.1 ms, total: 1.31 s\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train the DecisionTree model \n",
    "dt_model = DecisionTreeClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.51 s, sys: 0 ns, total: 4.51 s\n",
      "Wall time: 4.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train the RandomForest model \n",
    "rf_model = RandomForestClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.19 ms, sys: 0 ns, total: 6.19 ms\n",
      "Wall time: 5.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# MultinomialNB model prediction\n",
    "nb_preds = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.54 ms, sys: 0 ns, total: 3.54 ms\n",
      "Wall time: 3.29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# MultinomialNB model prediction\n",
    "dt_preds = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 65.4 ms, sys: 2.32 ms, total: 67.7 ms\n",
      "Wall time: 67.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# MultinomialNB model prediction\n",
    "rf_preds = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_recall = 0.9793720105851994\n",
      "dt_recall = 1.0\n",
      "rf_recall = 0.9999945211183493\n"
     ]
    }
   ],
   "source": [
    "#recall of each model\n",
    "nb_recall = recall_score(y_test, nb_preds, pos_label=0)\n",
    "dt_recall = recall_score(y_test, dt_preds, pos_label=0)\n",
    "rf_recall = recall_score(y_test, rf_preds, pos_label=0)\n",
    "\n",
    "print(f\"nb_recall = {nb_recall}\")\n",
    "print(f\"dt_recall = {dt_recall}\")\n",
    "print(f\"rf_recall = {rf_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_accuracy = 0.91979\n",
      "dt_accuracy = 0.999975\n",
      "rf_accuracy = 0.99997\n"
     ]
    }
   ],
   "source": [
    "# accuracy of each model\n",
    "nb_accuracy = nb_model.score(X_test, y_test)\n",
    "dt_accuracy = dt_model.score(X_test, y_test)\n",
    "rf_accuracy = rf_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"nb_accuracy = {nb_accuracy}\")\n",
    "print(f\"dt_accuracy = {dt_accuracy}\")\n",
    "print(f\"rf_accuracy = {rf_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb confusion matrix: \n",
      " [[178754   3765]\n",
      " [ 12277   5204]]\n",
      "\n",
      "dt confusion matrix: \n",
      " [[182519      0]\n",
      " [     5  17476]]\n",
      "\n",
      "rf confusion matrix: \n",
      " [[182518      1]\n",
      " [     5  17476]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_cm = confusion_matrix(y_test, nb_preds)\n",
    "dt_cm = confusion_matrix(y_test, dt_preds)\n",
    "rf_cm = confusion_matrix(y_test, rf_preds)\n",
    "\n",
    "print(f\"nb confusion matrix: \\n {nb_cm}\\n\")\n",
    "print(f\"dt confusion matrix: \\n {dt_cm}\\n\")\n",
    "print(f\"rf confusion matrix: \\n {rf_cm}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain why the data is too accurate?\n",
    "# decision tree actually look like\n",
    "# information gain per feature\n",
    "# finding the evidence \n",
    "# visualization PCA ? \n",
    "# altair "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
